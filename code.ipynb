{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJKDueOz9Wf1"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, silhouette_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import entropy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "wd = \"/content/drive/MyDrive/project/\""
      ],
      "metadata": {
        "id": "MoPDCreVNOLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3165f2aa-31aa-4789-e5d0-5bf7031a7bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8DKg-_w9Wf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf3faab-35be-42c7-bff7-109886f2eadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-da4b3b3eca7f>:2: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  points = pd.concat([pd.read_csv(f\"{wd}charting-m-points-2010s.csv\"), pd.read_csv(f\"{wd}charting-m-points-2020s.csv\")])\n"
          ]
        }
      ],
      "source": [
        "# Read in points csv\n",
        "points = pd.concat([pd.read_csv(f\"{wd}charting-m-points-2010s.csv\"), pd.read_csv(f\"{wd}charting-m-points-2020s.csv\")])\n",
        "# Create a function to read in match_data csv\n",
        "def read_match_data(yr):\n",
        "    data = pd.read_csv(f\"{wd}atp_matches_{yr}.csv\")\n",
        "    return(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 7-9 (return depth)\n",
        "pattern = r'[7-9]'\n",
        "# Use .str.replace() with regex=True to clean the \"point\" column\n",
        "points['1st'] = points['1st'].str.replace(pattern, '', regex=True)\n",
        "points['2nd'] = points['2nd'].str.replace(pattern, '', regex=True)"
      ],
      "metadata": {
        "id": "-BawOtTu14PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns from points Data Frame\n",
        "points = points[['match_id', 'Pt', 'PtWinner', 'Svr', '1st', '2nd']]\n",
        "# Split the match_id column\n",
        "points[['date', 'gender', 'event', 'round', 'p1', 'p2']] = points['match_id'].str.split('-', expand=True)\n",
        "# Remove '_' from p1 and p2\n",
        "points['p1'] = points['p1'].str.replace('_', ' ', regex=False)\n",
        "points['p2'] = points['p2'].str.replace('_', ' ', regex=False)\n",
        "# Set Svr and PtWinner cols. as names instead of numbers\n",
        "points['Svr'] = points.apply(lambda row: row['p1'] if row['Svr'] == 1 else row['p2'], axis = 1)\n",
        "points['PtWinner'] = points.apply(lambda row: row['p1'] if row['PtWinner'] == 1 else row['p2'], axis = 1)"
      ],
      "metadata": {
        "id": "Ssbuvhr6m6z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z92nnN6b9Wf5"
      },
      "outputs": [],
      "source": [
        "# Create an empty list to store the data\n",
        "data_list = []\n",
        "# Iterate through the years 2010-2024\n",
        "for yr in range(2010, 2025):\n",
        "    # Read the data for the current year\n",
        "    year_data = read_match_data(yr)\n",
        "    # Append the DataFrame to the list\n",
        "    data_list.append(year_data)\n",
        "# Concatenate all DataFrames in the list into a single DataFrame\n",
        "data = pd.concat(data_list, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kfuAxtw9Wf6"
      },
      "outputs": [],
      "source": [
        "def extract_tennis_point(example_string):\n",
        "    if pd.isna(example_string) or example_string is None:\n",
        "        return None, None, None  # Return None values for serve, rally, and final shot\n",
        "\n",
        "    # Pattern to extract serve based on criteria\n",
        "    serve_pattern = r'^[cC]*\\d[\\+\\*#]?[wndx!e]?'  # Matches serve + optional error suffix\n",
        "\n",
        "    serve_match = re.match(serve_pattern, example_string)\n",
        "\n",
        "    if serve_match:\n",
        "        serve = serve_match.group()\n",
        "        remaining_string = example_string[len(serve):]\n",
        "    else:\n",
        "        serve = None\n",
        "        remaining_string = example_string\n",
        "\n",
        "    # Pattern for rally shots\n",
        "    rally_pattern = r'[a-z]?[;\\\\+=^]?[1-3]?'\n",
        "    rally_shots = re.findall(rally_pattern, remaining_string)\n",
        "\n",
        "    # Pattern to extract the final shot\n",
        "    final_shot_pattern = r'[a-z][;\\\\+=^]?[1-3]?[nwdx!e]?[;\\\\+=^]?[@#\\*]'\n",
        "    final_shot_match = re.search(final_shot_pattern, remaining_string)\n",
        "\n",
        "    final_shot = None\n",
        "    if final_shot_match:\n",
        "        final_shot = final_shot_match.group()\n",
        "        final_shot_code = final_shot[:-1]\n",
        "\n",
        "        # Remove last 2 shots if final shot ends with '@' or '#', otherwise remove 1\n",
        "        if final_shot.endswith('@') or final_shot.endswith('#'):\n",
        "            rally_shots = rally_shots[:-3]\n",
        "        else:\n",
        "            rally_shots = rally_shots[:-2]\n",
        "\n",
        "    return serve, rally_shots, final_shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxCCnfWh9Wf6"
      },
      "outputs": [],
      "source": [
        "# Apply the function to '1st' and '2nd' columns\n",
        "points[['1st_serve', '1st_rally', '1st_final_shot']] = points['1st'].apply(\n",
        "    lambda x: pd.Series(extract_tennis_point(x) if pd.notna(x) else (None, None, None))\n",
        ")\n",
        "points[['2nd_serve', '2nd_rally', '2nd_final_shot']] = points['2nd'].apply(\n",
        "    lambda x: pd.Series(extract_tennis_point(x) if pd.notna(x) else (None, None, None))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all the shots\n",
        "shots_data = []\n",
        "\n",
        "for _, row in points.iterrows():\n",
        "    rally_shots = []\n",
        "    shot_types = []\n",
        "    shot_players = []\n",
        "    is_first_serve = []\n",
        "\n",
        "    # Function to process shots safely\n",
        "    def process_shots(shot_entry):\n",
        "        if isinstance(shot_entry, str):  # If it's a string, split it\n",
        "            return shot_entry.split(', ')\n",
        "        elif isinstance(shot_entry, list):  # If it's already a list, return as is\n",
        "            return shot_entry\n",
        "        else:  # If it's NaN or unexpected, return an empty list\n",
        "            return []\n",
        "\n",
        "    # Handle first serve\n",
        "    first_serve_shots = process_shots(row['1st_serve'])\n",
        "    rally_shots.extend(first_serve_shots)\n",
        "    shot_types.extend(['serve'] * len(first_serve_shots))\n",
        "    shot_players.extend([row['p1'] if row['Svr'] == row['p1'] else row['p2']] * len(first_serve_shots))\n",
        "    is_first_serve.extend([1] * len(first_serve_shots))\n",
        "\n",
        "    # Handle first rally\n",
        "    first_rally_shots = process_shots(row['1st_rally'])\n",
        "    rally_shots.extend(first_rally_shots)\n",
        "    shot_types.extend(['rally'] * len(first_rally_shots))\n",
        "    shot_players.extend([None] * len(first_rally_shots))\n",
        "    is_first_serve.extend([1] * len(first_rally_shots))\n",
        "\n",
        "    # Handle first final shot\n",
        "    first_final_shot = process_shots(row['1st_final_shot'])\n",
        "    rally_shots.extend(first_final_shot)\n",
        "    shot_types.extend(['final_shot'] * len(first_final_shot))\n",
        "    shot_players.extend([None] * len(first_final_shot))\n",
        "    is_first_serve.extend([1] * len(first_final_shot))\n",
        "\n",
        "    # Handle second serve\n",
        "    second_serve_shots = process_shots(row['2nd_serve'])\n",
        "    rally_shots.extend(second_serve_shots)\n",
        "    shot_types.extend(['serve'] * len(second_serve_shots))\n",
        "    shot_players.extend([row['p1'] if row['Svr'] == row['p1'] else row['p2']] * len(second_serve_shots))\n",
        "    is_first_serve.extend([0] * len(second_serve_shots))\n",
        "\n",
        "    # Handle second rally\n",
        "    second_rally_shots = process_shots(row['2nd_rally'])\n",
        "    rally_shots.extend(second_rally_shots)\n",
        "    shot_types.extend(['rally'] * len(second_rally_shots))\n",
        "    shot_players.extend([None] * len(second_rally_shots))\n",
        "    is_first_serve.extend([0] * len(second_rally_shots))\n",
        "\n",
        "    # Handle second final shot\n",
        "    second_final_shot = process_shots(row['2nd_final_shot'])\n",
        "    rally_shots.extend(second_final_shot)\n",
        "    shot_types.extend(['final_shot'] * len(second_final_shot))\n",
        "    shot_players.extend([None] * len(second_final_shot))\n",
        "    is_first_serve.extend([0] * len(second_final_shot))\n",
        "\n",
        "    # Assign alternating shot players after each serve\n",
        "    for i in range(len(shot_players)):\n",
        "        if shot_players[i] is None:\n",
        "            shot_players[i] = row['p1'] if shot_players[i - 1] == row['p2'] else row['p2']\n",
        "\n",
        "    # Add all shots to the new dataframe\n",
        "    for shot, shot_type, shot_player, first_serve_flag in zip(rally_shots, shot_types, shot_players, is_first_serve):\n",
        "        shots_data.append({\n",
        "            'match_id': row['match_id'],\n",
        "            'pt': row['Pt'],\n",
        "            'Svr': row['Svr'],\n",
        "            'p1': row['p1'],\n",
        "            'p2': row['p2'],\n",
        "            'shot': shot,\n",
        "            'shot_player': shot_player,\n",
        "            'shot_type': shot_type,\n",
        "            'rally_num': rally_shots.index(shot) + 1,\n",
        "            'PtWinner': row['PtWinner'],\n",
        "            'is_first_serve': first_serve_flag\n",
        "        })\n",
        "\n",
        "# Create new DataFrame with the shot-by-shot data\n",
        "df = pd.DataFrame(shots_data)"
      ],
      "metadata": {
        "id": "--sf2MXuOXSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# String detection\n",
        "# Identify shot types\n",
        "fh_shots = ['f', 'r', 'v', 'u', 'o', 'l', 'j', 'h']\n",
        "bh_shots = ['b', 's', 'z', 'p', 'y', 'm', 'i', 'k']\n",
        "slices = ['r', 's']\n",
        "volleys = ['v', 'j', 'h', 'z', 'i', 'k']\n",
        "drop_shot = ['u', 'y']\n",
        "overhead = ['o', 'p']\n",
        "lob = ['l', 'm']\n",
        "# Add in cols. for shot types\n",
        "df['fh'] = df['shot'].apply(lambda x: 1 if any(char in x for char in fh_shots) else 0)\n",
        "df['bh'] = df['shot'].apply(lambda x: 1 if any(char in x for char in bh_shots) else 0)\n",
        "df['slice'] = df['shot'].apply(lambda x: 1 if any(char in x for char in slices) else 0)\n",
        "df['volley'] = df['shot'].apply(lambda x: 1 if any(char in x for char in volleys) else 0)\n",
        "df['drop_shot'] = df['shot'].apply(lambda x: 1 if any(char in x for char in drop_shot) else 0)\n",
        "df['overhead'] = df['shot'].apply(lambda x: 1 if any(char in x for char in overhead) else 0)\n",
        "df['lob'] = df['shot'].apply(lambda x: 1 if any(char in x for char in lob) else 0)\n",
        "df['trick_shot'] = df['shot'].str.contains('t', na=False).astype(int)\n",
        "df['unknown_shot'] = df['shot'].str.contains('q', na=False).astype(int)\n",
        "# Detect point end\n",
        "df['ace'] = df.apply(lambda row: 1 if '*' in row['shot'] and row['shot_type'] == 'serve' else 0, axis=1)\n",
        "df['unreturned_serve'] = df.apply(lambda row: 1 if '#' in row['shot'] and row['shot_type'] == 'serve' else 0, axis=1)\n",
        "df['winner'] = df.apply(lambda row: 1 if '*' in row['shot'] and row['shot_type'] != 'serve' else 0, axis=1)\n",
        "df['forced_error'] = df.apply(lambda row: 1 if '#' in row['shot'] and row['shot_type'] != 'serve' else 0, axis=1)\n",
        "df['unforced_error'] = df.apply(lambda row: 1 if '@' in row['shot'] and row['shot_type'] != 'serve' else 0, axis=1)\n",
        "# Detect serve locs\n",
        "df['serve_wide'] = df['shot'].str.contains('4', na=False).astype(int)\n",
        "df['serve_body'] = df['shot'].str.contains('5', na=False).astype(int)\n",
        "df['serve_t'] = df['shot'].str.contains('6', na=False).astype(int)\n",
        "df['serve_unknown'] = df['shot'].str.contains('0', na=False).astype(int)\n",
        "# Detect error types\n",
        "df['net'] = df['shot'].str.contains('n', na=False).astype(int)\n",
        "df['wide'] = df['shot'].str.contains('w', na=False).astype(int)\n",
        "df['deep'] = df['shot'].str.contains('d', na=False).astype(int)\n",
        "df['deep_wide'] = df['shot'].str.contains('x', na=False).astype(int)\n",
        "df['shank'] = df['shot'].str.contains('!', na=False).astype(int)\n",
        "df['unknown_error'] = df['shot'].str.contains('e', na=False).astype(int)\n",
        "# Detect court position\n",
        "df['approach'] = df['shot'].str.contains('+', na=False, regex = False).astype(int)\n",
        "df['at_net'] = df['shot'].str.contains('-', na=False, regex = False).astype(int)\n",
        "df['at_baseline'] = df['shot'].str.contains('=', na=False, regex = False).astype(int)\n",
        "df['stop_volley'] = df['shot'].str.contains('^', na=False, regex = False).astype(int)\n",
        "df['drop_volley'] = df['shot'].str.contains('~', na=False, regex = False).astype(int)\n",
        "df['net_cord'] = df['shot'].str.contains(';', na=False, regex = False).astype(int)"
      ],
      "metadata": {
        "id": "VcuUf9jRdp0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get player handedness\n",
        "w_hand = data[['winner_name', 'winner_hand']].rename(columns={'winner_name': 'player', 'winner_hand': 'hand'})\n",
        "l_hand = data[['loser_name', 'loser_hand']].rename(columns={'loser_name': 'player', 'loser_hand': 'hand'})\n",
        "hand = pd.concat([w_hand, l_hand])\n",
        "hand.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "LZVFZ3Dmwept"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column for opponent\n",
        "df['opp_player'] = df.apply(lambda row: row['p2'] if row['shot_player'] == row['p1'] else row['p1'], axis = 1)\n",
        "# Join opponent with listed handedness\n",
        "df = pd.merge(df, hand, left_on='opp_player', right_on='player', how='left')"
      ],
      "metadata": {
        "id": "0RmNaT38zefM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect groundstroke locations\n",
        "df['to_fh'] = np.where((df['shot'].str.contains('1', na=False) & (df['hand'] == \"R\")) |\n",
        "                       (df['shot'].str.contains('3', na=False) & (df['hand'] == \"L\")), 1, 0)\n",
        "df['to_middle'] = df['shot'].str.contains('2', na=False).astype(int)\n",
        "df['to_bh'] = np.where((df['shot'].str.contains('3', na=False) & (df['hand'] == \"R\")) |\n",
        "                       (df['shot'].str.contains('1', na=False) & (df['hand'] == \"L\")), 1, 0)"
      ],
      "metadata": {
        "id": "OGa6Gkss9qd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build naïve bayes shot wp model (currently not accounting for specific player ability)\n",
        "# If the shot player won the point (response variable)\n",
        "df['player_win'] = df.apply(lambda row: 1 if row['shot_player'] == row['PtWinner'] else 0, axis = 1)\n",
        "# If the shot player hit the serve\n",
        "df['is_server'] = df.apply(lambda row: 1 if row['shot_player'] == row['Svr'] else 0, axis = 1)\n",
        "# If the shot type is a serve\n",
        "df['is_serve'] = df.apply(lambda row: 1 if row['shot_type'] == 'serve' else 0, axis = 1)"
      ],
      "metadata": {
        "id": "AeSZCEVOTW_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select model features from df for nb model\n",
        "model_features = df[['match_id', 'player_win', 'shot_player', 'is_server', 'is_first_serve', 'is_serve', 'rally_num', # Shot/point information\n",
        "    'serve_wide', 'serve_body', 'serve_t', # Serve information\n",
        "    'fh', 'bh', 'slice', 'volley', 'drop_shot', 'overhead', 'lob', # Shot type\n",
        "    'to_fh', 'to_middle', 'to_bh', # Shot location\n",
        "    'approach', 'at_net', 'at_baseline', 'stop_volley', 'drop_volley', 'net_cord' # Court position\n",
        "    ]]"
      ],
      "metadata": {
        "id": "oxMBTlp7T2C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "features = model_features.drop(columns=['player_win', 'match_id', 'shot_player', 'rally_num'])  # Drop the response and other variables\n",
        "response = model_features['player_win']  # Response variable\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, response, test_size=0.1, random_state=13210)\n",
        "test_data = model_features.loc[X_test.index]"
      ],
      "metadata": {
        "id": "OjC3zfGmkHhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Bernoulli Naïve Bayes model\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}')"
      ],
      "metadata": {
        "id": "qrJAAmQLmgZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6deb26f5-f9b9-452e-d537-4d36dd66b302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 56.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and apply model results onto model_features data\n",
        "y_pred = model.predict(X_test) # Classified result\n",
        "y_prob = model.predict_proba(X_test)[:, 1] # Probability\n",
        "# Add predictions back into the test dataset\n",
        "test_data['predicted_win'] = y_pred\n",
        "test_data['predicted_prob'] = y_prob"
      ],
      "metadata": {
        "id": "_4HTRgEr0JKY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create serve error rate cols\n",
        "df['wide_error'] = df.apply(lambda row: 1 if row['serve_wide'] == 1 and\n",
        " (row['net'] == 1 or row['wide'] == 1 or row['deep'] == 1 or row['deep_wide'] == 1) else 0, axis = 1)\n",
        "df['body_error'] = df.apply(lambda row: 1 if row['serve_body'] == 1 and\n",
        " (row['net'] == 1 or row['wide'] == 1 or row['deep'] == 1 or row['deep_wide'] == 1) else 0, axis = 1)\n",
        "df['t_error'] = df.apply(lambda row: 1 if row['serve_t'] == 1 and\n",
        " (row['net'] == 1 or row['wide'] == 1 or row['deep'] == 1 or row['deep_wide'] == 1) else 0, axis = 1)"
      ],
      "metadata": {
        "id": "10Bbb08htEuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fh/bh error/winner cols.\n",
        "df['fh_error'] = df.apply(lambda row: 1 if (row['fh'] == 1) and (row['unforced_error'] == 1 or row['forced_error'] == 1) else 0, axis = 1)\n",
        "df['bh_error'] = df.apply(lambda row: 1 if (row['bh'] == 1) and (row['unforced_error'] == 1 or row['forced_error'] == 1) else 0, axis = 1)\n",
        "df['fh_winner'] = df.apply(lambda row: 1 if row['fh'] == 1 and row['winner'] == 1 else 0, axis = 1)\n",
        "df['bh_winner'] = df.apply(lambda row: 1 if row['bh'] == 1 and row['winner'] == 1 else 0, axis = 1)"
      ],
      "metadata": {
        "id": "7B121aOpqY0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate shot data by player\n",
        "# Store individual serves and rallies data frames\n",
        "serves = df[df['shot_type'] == 'serve']\n",
        "rallies = df[df['shot_type'] != 'serve']\n",
        "# Aggregate serve data by player\n",
        "serve_data = serves.groupby('shot_player').agg({\n",
        "    'ace': 'sum',\n",
        "    'unreturned_serve': 'sum',\n",
        "    'serve_wide': 'sum',\n",
        "    'serve_body': 'sum',\n",
        "    'serve_t': 'sum',\n",
        "    'wide_error': 'sum',\n",
        "    'body_error': 'sum',\n",
        "    't_error': 'sum'\n",
        "\n",
        "}).assign(n=serves.groupby('shot_player').size()).reset_index()\n",
        "# Aggregate rally data by player\n",
        "rally_data = rallies.groupby('shot_player').agg({\n",
        "    'fh': 'sum',\n",
        "    'bh': 'sum',\n",
        "    'slice': 'sum',\n",
        "    'volley': 'sum',\n",
        "    'drop_shot': 'sum',\n",
        "    'to_fh': 'sum',\n",
        "    'to_middle': 'sum',\n",
        "    'to_bh': 'sum',\n",
        "    'fh_error': 'sum',\n",
        "    'bh_error': 'sum',\n",
        "    'fh_winner': 'sum',\n",
        "    'bh_winner': 'sum',\n",
        "    'winner': 'sum',\n",
        "    'forced_error': 'sum',\n",
        "    'unforced_error': 'sum',\n",
        "    'approach': 'sum',\n",
        "    'at_net': 'sum',\n",
        "    'at_baseline': 'sum',\n",
        "}).assign(n=rallies.groupby('shot_player').size()).reset_index()"
      ],
      "metadata": {
        "id": "VP0Xu-qqy4ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty data frame\n",
        "serve_df = pd.DataFrame()\n",
        "# Collect serve stats in a new serve_df\n",
        "serve_df['player'] = serve_data['shot_player']\n",
        "serve_df['ace_rate'] = serve_data['ace']/serve_data['n']\n",
        "serve_df['unreturned_serve_rate'] = serve_data['unreturned_serve']/serve_data['n']\n",
        "serve_df['wide_freq'] = serve_data['serve_wide']/serve_data['n']\n",
        "serve_df['body_freq'] = serve_data['serve_body']/serve_data['n']\n",
        "serve_df['t_freq'] = serve_data['serve_t']/serve_data['n']\n",
        "serve_df['wide_accuracy'] = serve_data['serve_wide']/(serve_data['serve_wide'] + serve_data['wide_error'])\n",
        "serve_df['body_accuracy'] = serve_data['serve_body']/(serve_data['serve_body'] + serve_data['body_error'])\n",
        "serve_df['t_accuracy'] = serve_data['serve_t']/(serve_data['serve_t'] + serve_data['t_error'])"
      ],
      "metadata": {
        "id": "_Aezw2qkqJfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty data frame\n",
        "rally_df = pd.DataFrame()\n",
        "# Collect rally stats in a new rally_data_df\n",
        "rally_df['player'] = rally_data['shot_player']\n",
        "rally_df['fh_rate'] = rally_data['fh']/rally_data['n']\n",
        "rally_df['bh_rate'] = rally_data['bh']/rally_data['n']\n",
        "rally_df['slice_rate'] = rally_data['slice']/rally_data['n']\n",
        "rally_df['volley_rate'] = rally_data['volley']/rally_data['n']\n",
        "rally_df['drop_shot_rate'] = rally_data['drop_shot']/rally_data['n']\n",
        "rally_df['to_fh_rate'] = rally_data['to_fh']/rally_data['n']\n",
        "rally_df['to_middle_rate'] = rally_data['to_middle']/rally_data['n']\n",
        "rally_df['to_bh_rate'] = rally_data['to_bh']/rally_data['n']\n",
        "rally_df['fh_accuracy'] = (rally_data['fh'] - rally_data['fh_error'])/(rally_data['fh'])\n",
        "rally_df['bh_accuracy'] = (rally_data['bh'] - rally_data['bh_error'])/(rally_data['bh'])\n",
        "rally_df['fh_winner_rate'] = rally_data['fh_winner']/rally_data['fh']\n",
        "rally_df['bh_winner_rate'] = rally_data['bh_winner']/rally_data['bh']\n",
        "rally_df['winner_rate'] = rally_data['winner']/rally_data['n']\n",
        "rally_df['ue_rate'] = rally_data['unforced_error']/rally_data['n']\n",
        "rally_df['fe_rate'] = rally_data['forced_error']/rally_data['n']\n",
        "rally_df['in_rate'] = 1 - (rally_df['ue_rate'] + rally_df['fe_rate'])\n",
        "rally_df['approach_rate'] = rally_data['approach']/rally_data['n']"
      ],
      "metadata": {
        "id": "jDggWHdXylrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(df, cols):\n",
        "    # Number of categories\n",
        "    n = len(cols)\n",
        "\n",
        "    # Sum the occurrences for each row\n",
        "    total = df[cols].sum(axis=1)\n",
        "\n",
        "    # Calculate probabilities (avoid division by zero)\n",
        "    probs = df[cols].div(total, axis=0).replace(0, np.nan)  # Replace 0s with NaN to avoid log issues\n",
        "\n",
        "    # Compute entropy row-wise and normalize\n",
        "    return probs.apply(lambda x: entropy(x, base=2) / np.log2(n), axis=1)\n",
        "\n",
        "# Apply entropy function to cols in the dataframe\n",
        "serve_df['serve_loc_entropy'] = calculate_entropy(serve_df, ['wide_freq', 'body_freq', 't_freq'])\n",
        "rally_df['shot_loc_entropy'] = calculate_entropy(rally_df, ['to_fh_rate', 'to_middle_rate', 'to_bh_rate'])\n",
        "# Get shot mix entropy\n",
        "rally_df['regular_rate'] = 1 - rally_df['slice_rate'] + rally_df['volley_rate'] + rally_df['drop_shot_rate']\n",
        "rally_df['shot_mix_entropy'] = calculate_entropy(rally_df, ['fh_rate', 'bh_rate', 'regular_rate', 'slice_rate', 'volley_rate', 'drop_shot_rate'])\n",
        "rally_df['fh_to_bh_rate'] = rally_df['fh_rate']/rally_df['bh_rate']"
      ],
      "metadata": {
        "id": "2vkH5dVYyXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_data = pd.merge(serve_df, rally_df, on='player')"
      ],
      "metadata": {
        "id": "KxO1imzYGLKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate match data by player\n",
        "# Get data split by winners\n",
        "winners = data[['winner_name', 'winner_ht', 'minutes', 'w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon', 'w_2ndWon', 'w_SvGms', 'w_bpSaved', 'w_bpFaced',\n",
        "                'loser_name', 'loser_ht', 'l_svpt', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved', 'l_bpFaced']].rename(\n",
        "    columns={'winner_name': 'player', 'winner_ht': 'ht', 'w_ace': 'ace', 'w_df': 'df', 'w_svpt': 'svpt', 'w_1stIn': 'first_in', 'w_1stWon': 'first_win',\n",
        "             'w_2ndWon': 'second_win', 'w_SvGms': 'svgms', 'w_bpSaved': 'bp_saved', 'w_bpFaced': 'bp_faced', 'loser_ht': 'opp_ht',\n",
        "             'l_svpt': 'return_pts', 'l_1stIn': 'first_returns', 'l_1stWon': 'first_return_wins', 'l_2ndWon': 'second_return_wins', 'loser_name': 'opp_name',\n",
        "             'l_SvGms': 'return_gms', 'l_bpSaved': 'bp_att', 'l_bpFaced': 'bp_won'}\n",
        ")\n",
        "winners['res'] = 1\n",
        "# Get data split by losers\n",
        "losers = data[['loser_name', 'loser_ht', 'minutes', 'w_svpt', 'l_ace', 'l_df', 'l_svpt', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved', 'l_bpFaced',\n",
        "                'winner_name', 'winner_ht', 'w_1stIn', 'w_1stWon', 'w_2ndWon', 'w_SvGms', 'w_bpSaved', 'w_bpFaced']].rename(\n",
        "    columns={'loser_name': 'player', 'loser_ht': 'ht', 'l_ace': 'ace', 'l_df': 'df', 'l_svpt': 'svpt', 'l_1stIn': 'first_in', 'l_1stWon': 'first_win',\n",
        "             'l_2ndWon': 'second_win', 'l_SvGms': 'svgms', 'l_bpSaved': 'bp_saved', 'l_bpFaced': 'bp_faced', 'winner_ht': 'opp_ht', 'winner_name': 'opp_name',\n",
        "             'w_1stIn': 'first_returns', 'w_1stWon': 'first_return_wins', 'w_2ndWon': 'second_return_wins', 'w_svpt': 'return_pts',\n",
        "             'w_SvGms': 'return_gms', 'w_bpSaved': 'bp_att', 'w_bpFaced': 'bp_won'}\n",
        ")\n",
        "losers['res'] = 0\n",
        "# Aggregate winner/loser data\n",
        "match_data = pd.concat([winners, losers])"
      ],
      "metadata": {
        "id": "2NZkBLReR5kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate data\n",
        "stats = match_data.groupby('player').agg({\n",
        "    'minutes': 'sum',\n",
        "    'ace': 'sum',\n",
        "    'df': 'sum',\n",
        "    'svpt': 'sum',\n",
        "    'first_in': 'sum',\n",
        "    'first_win': 'sum',\n",
        "    'second_win': 'sum',\n",
        "    'svgms': 'sum',\n",
        "    'bp_saved': 'sum',\n",
        "    'bp_faced': 'sum',\n",
        "    'opp_ht': 'sum',\n",
        "    'return_pts': 'sum',\n",
        "    'first_returns': 'sum',\n",
        "    'first_return_wins': 'sum',\n",
        "    'second_return_wins': 'sum',\n",
        "    'return_gms': 'sum',\n",
        "    'bp_att': 'sum',\n",
        "    'bp_won': 'sum'\n",
        "}).reset_index()\n",
        "stats['first_pct'] = stats['first_in']/stats['svpt']\n",
        "stats['first_win_pct'] = stats['first_win']/stats['first_in']\n",
        "stats['second_pct'] = (stats['svpt'] - stats['first_in'] - stats['df'])/(stats['svpt'] - stats['first_in'])\n",
        "stats['second_win_pct'] = stats['second_win']/(stats['svpt'] - stats['first_in'] - stats['df'])\n",
        "stats['first_return_win_pct'] = stats['first_return_wins']/stats['first_returns']\n",
        "stats['second_return_win_pct'] = stats['second_return_wins']/(stats['return_pts'] - stats['first_returns'])\n",
        "stats['bp_saved_pct'] = stats['bp_saved']/stats['bp_faced']\n",
        "stats['bp_won_pct'] = stats['bp_won']/stats['bp_att']\n",
        "stats['svgm_win_pct'] = (stats['svgms'] - (stats['bp_faced'] - stats['bp_saved']))/stats['svgms']\n",
        "stats['retgm_win_pct'] = stats['bp_won']/stats['return_gms']"
      ],
      "metadata": {
        "id": "MS1MfWITT7Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine aggregated shot data with aggregated match data for cluster model dataset\n",
        "# Create a serve_rates Data Frame\n",
        "serve_rates = stats[['player', 'first_pct', 'second_pct']]\n",
        "# Join cluster and serve Data Frames to build cluster model\n",
        "cluster_data = pd.merge(cluster_data, serve_rates, on='player', how = 'left').dropna()"
      ],
      "metadata": {
        "id": "asUgBeAvy-TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select cluster_data features\n",
        "cluster_features = cluster_data[['player', 'ace_rate', 'serve_loc_entropy', 'shot_loc_entropy', 'shot_mix_entropy',\n",
        "              'fh_to_bh_rate', 'winner_rate', 'in_rate', 'ue_rate', 'fe_rate']]"
      ],
      "metadata": {
        "id": "C-ZimCmIzyOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build cluster model to get player types based on match and shot data\n",
        "cluster_model_data = cluster_features.drop(columns=['player']).values\n",
        "# Find the best number of clusters using silhouette score\n",
        "best_k = 2  # Start with at least 2 clusters\n",
        "best_score = -1  # Initialize to a low value\n",
        "silhouette_scores = {}\n",
        "\n",
        "for k in range(2, 11):  # Test clusters from 2 to 10\n",
        "    kmeans = KMeans(n_clusters=k, random_state=13210, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(cluster_model_data)\n",
        "    score = silhouette_score(cluster_model_data, cluster_labels)\n",
        "\n",
        "    silhouette_scores[k] = score\n",
        "    if score > best_score:\n",
        "        best_k = k\n",
        "        best_score = score\n",
        "\n",
        "print(f'Optimal number of clusters: {best_k} with silhouette score: {best_score:.3f}')"
      ],
      "metadata": {
        "id": "2Qf01Bbbz-zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the final K-Means model with the optimal number of clusters\n",
        "final_kmeans = KMeans(n_clusters=best_k, random_state=13210, n_init=25)\n",
        "# Apply cluster results onto cluster data\n",
        "cluster_data['cluster'] = final_kmeans.fit_predict(cluster_model_data)\n",
        "# Check cluster assignments\n",
        "clusters = cluster_data[['player', 'cluster']]"
      ],
      "metadata": {
        "id": "O7Fut0l4Dxci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Data Frame with match and cluster data\n",
        "match_data_with_clusters = pd.merge(match_data, clusters, left_on='opp_name', right_on = 'player', how = 'left')\n",
        "# Collect win data by cluster\n",
        "wins = match_data_with_clusters.groupby(['player_x', 'cluster']).agg({\n",
        "    'res': 'sum'\n",
        "}).assign(n=match_data_with_clusters.groupby(['player_x', 'cluster']).size()).reset_index()\n",
        "wins['win_pct'] = wins['res']/wins['n']\n",
        "cluster_win_pct = wins[['player_x', 'cluster', 'win_pct']].rename(columns={'player_x': 'player'})"
      ],
      "metadata": {
        "id": "aixoKbuF6Egg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create matches Data Frame (with selected cols.)\n",
        "matches = data[['tourney_id', 'tourney_name', 'tourney_date', 'winner_name', 'loser_name']]\n",
        "# Create a 'winner' column based on the winner_name\n",
        "matches['winner'] = matches['winner_name']\n",
        "# Randomly shuffle 50% of matches\n",
        "mask = np.random.rand(len(matches)) < 0.5\n",
        "# Apply mask to have the data\n",
        "matches.loc[mask, [\"p1\", \"p2\"]] = matches.loc[mask, [\"winner_name\", \"loser_name\"]].values\n",
        "matches.loc[~mask, [\"p1\", \"p2\"]] = matches.loc[~mask, [\"loser_name\", \"winner_name\"]].values\n",
        "# Modify winner column\n",
        "matches['p1_win'] = matches.apply(lambda row: 1 if row['p1'] == row['winner'] else 0, axis = 1)\n",
        "# Select cols. for Data Frame\n",
        "matches = matches[['tourney_id', 'tourney_name', 'tourney_date', \"p1\", \"p2\", \"p1_win\"]]"
      ],
      "metadata": {
        "id": "q-0YX1ek8oo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify stats Data Frame\n",
        "stats = stats[['player', 'first_pct', 'first_win_pct', 'second_pct', 'second_win_pct', 'first_return_win_pct',\n",
        "               'second_return_win_pct', 'bp_saved_pct','bp_won_pct', 'svgm_win_pct', 'retgm_win_pct']]"
      ],
      "metadata": {
        "id": "E1AbUcHS89Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join p1 data first\n",
        "stats_p1 = pd.merge(matches, stats, left_on='p1', right_on='player', how='left', suffixes=(\"\", \"_other\"))\n",
        "stats_p1 = pd.merge(stats_p1, cluster_features, left_on='p1', right_on='player', how='left', suffixes=(\"\", \"_other\"))\n",
        "stats_p2 = pd.merge(stats_p1, stats, left_on='p2', right_on='player', how='left', suffixes=(\"\", \"_p2\"))\n",
        "stats_p2 = pd.merge(stats_p2, cluster_features, left_on='p1', right_on='player', how='left', suffixes=(\"\", \"_other\"))\n",
        "# Apply cluster results\n",
        "cluster_matches = pd.merge(stats_p1, clusters, left_on = ['p2'], right_on = [\"player\"], how = 'left', suffixes=(\"\", \"2\"))\n",
        "rf_data = pd.merge(cluster_matches, cluster_win_pct, left_on = ['p2', 'cluster'], right_on = [\"player\", \"cluster\"], how = 'left', suffixes=(\"\", \"_other\"))\n",
        "rf_data = rf_data.dropna()\n",
        "rf_data = rf_data[~rf_data.isin([np.inf, -np.inf]).any(axis=1)]"
      ],
      "metadata": {
        "id": "zpu8OglO-QQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_data.drop(columns=[\"p1\", \"p2\", \"player\", \"p1_win\", \"player2\", \"player_other\"])"
      ],
      "metadata": {
        "id": "r6JfxTEFYWL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Random Forest match win classification model\n",
        "# Want to apply k-fold cv\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = rf_data.drop(columns=[\"tourney_name\", \"tourney_id\", \"tourney_date\", \"p1\", \"p2\", \"player\", \"p1_win\", \"player2\", \"player_other\"])  # Replace 'target_column' with your actual target\n",
        "y = rf_data['p1_win']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13210)\n",
        "\n",
        "test_data = rf_data.loc[X_test.index]\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=13210)  # Change to RandomForestRegressor() for regression\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "NniAVMfS7-LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1] # Probability for event\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred) # Correct/correct + incorrect\n",
        "precision = precision_score(y_test, y_pred) # True positives/true positives + false positives\n",
        "recall = recall_score(y_test, y_pred) # True positives/true positives + false negatives\n",
        "f1 = f1_score(y_test, y_pred) # 2 x precision x recall/precision + recall\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Model Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Model Recall: {recall * 100:.2f}%\")\n",
        "print(f\"Model F1: {f1 * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "AUx9bKoBvT7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your true labels (y_true) and predicted labels (y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Create a heatmap using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "3TCDBS_rwP3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['p1_wp'] = y_prob\n",
        "test_data['p2_wp'] = 1 - test_data['p1_wp']\n",
        "test_data[['tourney_name', 'tourney_date', 'p1', 'p2', 'p1_win', 'p1_wp', 'p2_wp']]"
      ],
      "metadata": {
        "id": "jAfoFosOEVes"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}